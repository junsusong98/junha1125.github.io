---
layout: post
title: 【Paper】 Mask R-CNN 논문 핵심 정리
description: > 
    Mask R-CNN 논문의 핵심만 직접 정리해 적어놓은 내용입니다. 
---

Mask R-CNN 논문 핵심 정리     
[이전 게시물](https://junha1125.github.io/artificial-intelligence/2020-04-13-1mask-rcnn/)도 참고하시는 것을 추천드립니다.


# 1. FCN (Fully Convolutional Network) 
 - Pixel wise Classification : 이미지 각 pixel에 대한 Classification 수행  
    = Pixel Grid by Grid로 Softmax값이 추출된다. 
 - Segmentation Annotation 기법 2가지 방법
    - 1 depth를 이용하는 첫번째 방법
    - Class 갯수 depth를 이용하는 두번째 방법
    - coco - mask 데이터의 다각형 꼭지점 값 이용.

 <p align="center"><img src='https://user-images.githubusercontent.com/46951365/92302723-4be48380-efa9-11ea-939a-5d2ee3671f17.png' alt='drawing' width='500'/></p>

 - Encoder & Decoder 기법
    - Dimension Reduction 하여 응축된 정보를 가지고 (위치 정보 소실) 다시 복원(Upsampling) 하는 과정을 거친다.

 <p align="center"><img src='https://user-images.githubusercontent.com/46951365/92302748-877f4d80-efa9-11ea-81f0-7febb18f73e0.png' alt='drawing' width='500'/></p>

 - FCN architecture : 사진 속 필기 확인하기
    - De-Convolution : convolution 기법을 반대로 수행하는 것이 아니다. 보간법(bilinear interpolation)을 사용한다. 이것을 통해서 복구를 하는 것이다. 최대한 비슷하게... 

 <p align="center"><img src='https://user-images.githubusercontent.com/46951365/92303180-7cc6b780-efad-11ea-9c5f-0b3537f3eb1b.png' alt='drawing' width='500'/></p>

- Feature Map을 혼합한 Sementic Segmentation
    - FCN 32 :   
        (width, hight) -> (width/32, hight/32) -> (width, hight)
    - FCN 16 :  
        (width, hight) -> (width/32, hight/32)x2 + (width/16, hight/16) -> (width, hight)
    - FCN 8 :  
        (width, hight) -> (width/32, hight/32)x4 + (width/16, hight/16)x2 + (width/8, hight/8)-> (width, hight)

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/92303325-a8966d00-efae-11ea-82b4-4db6244d5848.png' alt='drawing' width='500'/></p>

# 2. Mask RCNN

- Mask R-CNN 핵심
    - Faster Rcnn + FCN 
    - ROI Align
    - Binary Mask Rediction 
    - 비교적 빠른 수행 시간
    - 비교적 높은 정확도
    - 직관적이고 상대적으로 쉬운 구현

- [이전 게시물](https://junha1125.github.io/artificial-intelligence/2020-04-13-1mask-rcnn/) 핵심 이미지 - Mask-RCNN을 한눈에 표현함
<p align="center"><img src='https://user-images.githubusercontent.com/46951365/92304774-f6fe3880-efbb-11ea-8d3c-6afe8ee8ee37.png' alt='drawing' width='600'/></p>

- ROI Pooling의 문제점 
    - 아래 이미지 참조. quantization을 2번 거친다. (= 실수의 반올림을 2번 한다.) 
    - 아래의 이미지의 2번쨰 quantization(B1)은 아래와 같은 과정을 거칠 수도 있지만,   
        Grid의 나눔을 불균등하게 하는 방법(B2)도 있다. (B1 - 5 = 2 + 2 + (1 버림) OR B2- 5 = 3 + 2)
    - 때문에 정확한 Pooling이 이뤄지지 못한다.

    <p align="center"><img src='https://user-images.githubusercontent.com/46951365/92352339-d697c080-f118-11ea-9f89-0ef39ee8c0ca.png' alt='drawing' width='650'/></p>

## 2-1 ROI Align - ROI Pooling 문제점 해결

- ROI Align : [이전 Post](https://junha1125.github.io/artificial-intelligence/2020-04-13-1mask-rcnn/) 55 슬라이드 부터 참조. 가장 중요한 부분 첨부
    - 순서 정리([꼭 이 사이트 그림 참조](https://towardsdatascience.com/understanding-region-of-interest-part-2-roi-align-and-roi-warp-f795196fc193))  
        1. Input-EachROI. output-7x7(nxn) Pooled Feature. 
        2. nxn등분(첫번째 quantization)
        3. 각4등분(두번째 quantization)->[Bilinear interpolation](https://towardsdatascience.com/understanding-region-of-interest-part-2-roi-align-and-roi-warp-f795196fc193)
        4. 각4등분에 대해 Max Pooling->(nxn) Pooled Feature Map 획득.
        5. 아래 이미지 참조 (아래 빨간 메모 꼭 읽기)

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/92364026-647da680-f12d-11ea-980f-b885086cea8f.png' alt='drawing' width='650'/></p>

- ROI Pooling 대신에 ROI Align을 적용해서 AP 성능 향상을 3~4% 할 수 있었다. 

## 2-2 Backbone과 Loss function
- Fearture Extractor (BackBone) : Resnet + Feature Pyramid Network

- Totoal Loss = L_cls + L_bbox + L_mask
    - L_cls = Multiclass cross-entropy loss (Softmax)
    - L_bbox = Smooth L1 loss
    - L_mask = Binary cross-entropy loss(해당 픽셀이 Classification에서 찾  Object class인지 아닌지(Sigmoid 사용))
- Mask Prediction
    - 7 x 7 x 2048이 14 x 14 x 256으로 Upsampling된다. 
    - 14 x 14 x 256은 14 x 14 x 80이 되어서, COCO 80개 Class에 대한 이진 Binary mask prediction값이 나온다. (아래 오른쪽 이미지의 Prediced Mask)
    - Prediced Mask(14 x 14)를 Upsampling하여 Resized Mask가 되도록 만든다. 

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/92365395-c7bc0880-f12e-11ea-9810-89cd57ab8717.png' alt='drawing' width='650'/></p>

## 2-3 성능 
- Instance Segmentation에서 좋은 성능이 나오는 것을 확인할 수 있다. 

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/92366067-a0b20680-f12f-11ea-931e-cc48ff2913a1.png' alt='drawing' width='550'/></p>
