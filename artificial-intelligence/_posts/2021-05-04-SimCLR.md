---
layout: post
title: 【Self】 Contrastive-learning based - SimCLR
---

- **Paper**: [SimCLR A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf), ICML 2020 
- **Reference site**:  [Youtube presentation link](https://www.youtube.com/watch?v=FWhM3juUM6s)
- **Contents**
  1. Paper review
  2. Youtube presentation summary
  3. Youtube presentaion material





---

# A Simple Framework for Contrastive Learning

# 1. Conclusion, Abstract

- ㅇ



---

# 2. Instruction, Relative work

- ㅇ



---

# 3. Method

- ㅇ



---

# 4. Experiments

- ㅇ



---

# 5. Results

- ㅇ



---

---

# Youtube presentation summary

참고 하면 좋을 자료: [illustrated-simclr](https://amitness.com/2020/03/illustrated-simclr/)

Pretext-tasks(=proxy-tasks)는 너무(ad-hoc) heuristics해서 `the generality of learn representations`에 한계가 있다. 

**Contrastive learning의 직관**

![image-20210504201301701](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210504201301701.png?raw=tru)

**SimCLR의 전체 요약**

![image-20210504201948328](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210504201948328.png?raw=tru)

**SimCLR 추가 개념 정리**

1. Random(stochastic)하게 data augmentation을 사용한다. 사용하는 Transform은 (1) Random crop and resize(with random flip) (2) color distortions (3) Gaussian blur를 사용한다. 
2. 위 이미지의 `f`는 ResNet50이고, `g`는 Two layer MLP(including ReLU)이다. 
3. Hard negative mining이 MoCo에서는 굉장히 중요했지만, 여기서는 Batch를 매우 크게 하면 대부분 Negative일 것이라 믿고 큰 Batch size를 사용한다. 
4. Temperature를 사용하는 Cosine similarity function을 사용한다.
5. Contrastive loss는 `Normalized temperature-scaled cross entropy(NT-Xent)` 라고 명명한 Loss를 사용했다. (위 사진의 Normalized cross entropy와 비슷하지만, 정확하게는 pseudo code에 define한 함수이다.)
6. Batch size 4096를 Default로 사용한다. 
7. 아래에 나오는 Self-supervised evaluation 방법으로는 linear evaluation protocol(Backbone freeze하고 1 layer FC만을 학습시킨다)을 사용한다. 
8. 하나의 이미지에 대해서 Transform을 적용하지 않은 것과, 2개의 Augmentaion을 랜덤으로 적용하여 학습시켰을 때 가장 효과적인 방법은 `Crop & Resize + Random color distortion` 이다. 특히 더 강한 color distortion을 적용할 수록 더 좋은 성능을 얻을 수 있었다. 
9. h = f(x) / z = g(f(x)) 라고 했을 때, z를 사용해서 Downstream task를 적용하는 것은 좋지 않다. z는 이미 invariant to data transformation 이기 때문이다. 이 특성은 New downstream task 모델을 학습시키는데 방해가 된다. 
10. NT-Xent Loss function은 hard-easy nagative를 분별하고 가중치를 다르게 줄 수 있는 능력을 가지고 있다. 그래서 Hard negative mining 기법을 사용할 필요가 없다.
11. the more epoch and batch size is, the better performance
12. Conclusion!
    - SimCLR의 핵심은 (1) the choice of data augmentation (2) the use of nonlinear head at the end of the network(`g`에서 RelU를 사용한 MLP) (3) the loss function
    - data augmentation으로 무엇을 사용하는지는 contrastive self-training에서 매우 중요하다.



# Youtube presentaion material
![img01](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-01.png?raw=true)
![img02](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-02.png?raw=true)
![img03](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-03.png?raw=true)
![img04](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-04.png?raw=true)
![img05](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-05.png?raw=true)
![img06](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-06.png?raw=true)
![img07](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-07.png?raw=true)
![img08](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-08.png?raw=true)
![img09](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-09.png?raw=true)
![img10](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-10.png?raw=true)
![img11](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-11.png?raw=true)
![img12](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-12.png?raw=true)
![img13](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-13.png?raw=true)
![img14](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-14.png?raw=true)
![img15](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-15.png?raw=true)
![img16](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-16.png?raw=true)
![img17](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-17.png?raw=true)
![img18](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-18.png?raw=true)
![img19](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-19.png?raw=true)
![img20](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-20.png?raw=true)
![img21](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-21.png?raw=true)
![img22](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-22.png?raw=true)
![img23](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-23.png?raw=true)
![img24](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-24.png?raw=true)
![img25](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-25.png?raw=true)
![img26](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-26.png?raw=true)
![img27](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-27.png?raw=true)
![img28](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-28.png?raw=true)
![img29](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-29.png?raw=true)
![img30](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-30.png?raw=true)
![img31](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-31.png?raw=true)
![img32](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-32.png?raw=true)
![img33](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-33.png?raw=true)
![img34](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-34.png?raw=true)
![img35](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-35.png?raw=true)
![img36](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-36.png?raw=true)
![img37](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-37.png?raw=true)
![img38](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-38.png?raw=true)
![img39](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-39.png?raw=true)
![img40](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/2021-5/9_SimCLR-Youtube/9_SimCLR-Youtube-40.png?raw=true)





















