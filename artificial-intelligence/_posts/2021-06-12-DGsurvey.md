---
layout: post
title: 【DG】 IntraDA & DG survey
---

- **Paper**: [Unsupervised Intra-domain Adaptation for Semantic Segmentation through Self-Supervision](https://arxiv.org/pdf/2004.07703.pdf)
- **Type**: DA 
- **Reference site**: [CVPR oral presentation](https://www.youtube.com/watch?v=x1KLka4iQlo)*



흥미로운 Paper List

1) Contrastive Syn-to-Real Generalization \[[paper](https://arxiv.org/pdf/2104.02290.pdf), [code](https://github.com/NVlabs/CSG)\] = Transfer Learning 목적으로 하는 DG 모델







# IntraDA 핵심요약

![image-20210612142726957](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210612142726957.png?raw=tru)

Domain Gap의 종류 2가지

1. Inter-domain gap: Source와 Target 간의 Doamin gap. 
2. Intra-domain gap: Target 내부에서 Hard와 Easy Image의 gap

위 2가지 Gap을 모두 줄이기 위해 노력한다!!

Method 핵심

1. Target domain에서 `Entropy-based ranking function`을 사용해, Easy와 Hard로 분리한다.
2. Easy images의 pseudo labels을 사용해서 Hard Images와의 Intra-Domain Adaptation을 수행한다. 
3. 전체 프레임은 3개로 구성되어 있다. (1) Inter-domain Adaptation (2) Entropy-based Ranking System (3) Intra-domain Adaptation

![image-20210612144838825](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210612144838825.png?raw=tru)

1. **Inter-domain adaptation**
   - ADVENT 그대로.
   - the Entropy of predictions 사용
2. **Entropy-based ranking**
   - 위에서 학습된 Generater사용한다.
   - Target image의 prediction과 Entropy가 생성된다. 
   - Lambda는 hard와 easy의 비율.
3. **Intra-domain adaptation**
   - Intra-Generator와 Intra-Discriminator로 구성되어 있다. 
   - Intra-Generator는 Target Easy Image의 Segmentation 결과를 생성한다.





# Domain Generalization Survey 핵심 요약

**진짜 핵심만 작성해라!!! 너무 당연한 얘기. 대강 알것 같은 이야기는 적지 말아라! 위에서 했던 소리 또한 다시 적지 말아라!!**

# 1. Introduction & Related Topics

- DG:  오직 source만을 사용해서, out-of-distribution data = unseen data에 대한 일반화 성능 향상을 목표로 한다." 이를 위한 방법으로 domain alignment, meta-learning, data augmentation, ensemble learning 과 같은 기법을 기반으로 사용한다.
- 용어 정리    
  <img src="C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210618214944482.png" alt="image-20210618214944482" style="zoom: 60%;" />
- DG 종류
  1. Multi-source DG
  2. Single-source DG
  3.  Homogeneous DG: the same set of classes 를 예측한다. 
  4. Heterogeneous DG: the different set of classes 를 예측한다. Zero-shot DG 라고도 할 수 있다. 새로운 클래스를 인지하는데도 도움이 되는 `generalizable feature representation` 를 학습하는 것을 목적으로 한다.
- Domain을 고려하는 Task들의 종류 
  1. Supervised Learning 
  2. Multi-Task Learning: 대부분 파라미터를 쉐어링하는 방법으로 모델 만든다.
  3. Transfer Learning := fine-tunning. 최근 이 관점의 DG works들은 transferable features(Adjustable parameter)를 만드는 것을 목적으로 한다.
  4. Zero-shot learning: Class space  changes를 고려해고, 새로운 Class도 예측할 줄 알게 만드는 것이 목적이다. attributes(클래스 특성)을 학습하는게 목적이다. attribute에 대한 예시는 아래와 같다.   
     ![image-20210618220756748](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210618220756748.png)



![image-20210618215409957](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210618215409957.png)





# 2.  METHODOLOGIES

## 2.1 Domain Alignment







## 2.2 Meta-Learning









## 2.3 Data Augmentation







## 2.4 Ensemble Learning







## 2.5 Network Architecture Design







## 2.6  Self-Supervised Learning







## 2.7 Learning Disentangled Representations







## 2.8 Invariant Risk Minimization









## 2.9 Training Heuristics









## 2.10 Side Information







