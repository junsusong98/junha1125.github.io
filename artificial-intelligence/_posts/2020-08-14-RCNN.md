---
layout: post
title: 【Paper】 RCNN(Regions with CNN), SPP(Spatial Pyramid Pooling), Fast RCNN
description: >
  당연하다고 생각하지만, RCNN 개념을 다시 상기하고 정리해보면서 공부해볼 예정이다.
---

RCNN(Regions with CNN) 계열에 대한 고찰과 공부

# 1. RCNN  

- 초기의 방식 - Sliding Wnidow 방식과 Selective Search 기반의 Region Propsal 방식
- RCNN은 Selective Search 을 사용한다. 

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91649423-f5f67400-eaae-11ea-9c86-1d769a8c36dd.png' alt='drawing' width='600'/></p>

- 위의 사진에서 Bounding Box Regression에서 나오는 값은 사실 중앙좌표와 box크기 x,y,w,h 이다. 
- 위의 사진에서 Softmax를 적용하는게 아니라, [SVM Classifier](http://hleecaster.com/ml-svm-concept/)(Class를 구분하는 직선,평면을 찾는다)을 사용했다. Train 시킬때는 Softmax를 사용하고 Inference에서는 SVM을 사용함으로써 성능향상을 보았다고 한다. 
- Selective Search를 통해서 나온 이미지를 AlexNet에 넣기위해서 227*227을 만들어야 하기 때문에, Crop, Warp를 적용했다. (ROI Pooling과 같은 느낌)
- Bounding Box Reggresion에서 좀더 정확한 Bounding Box를 찾아낸다. 

### 1-1 RCNN 특징 및 의의
- CNN을 통과하는 과정이 대략 2000개의 ROI에 모두 적용하므로 시간이 매우 오래걸린다.
- 그 시기에 높은 Detection 정확도를 가졌지만, 너무 느리다. 
- 복잡한 프로세스 떄문에, 학습 및 모델 코드 구현이 매우 복잡하고 어렵다. 
- 각각의 Selective Search, Feature Extractor, FC layer, Box Regression 등이 서로 따로 놀아서 구현 및 다루기가 매우 힘들다. 
- 딥러닝 기반 Object Detection 성능을 입증
- Region Proposal 기반 성능 입증
- 위와 같은 복잡한 프로세스의 통합 연구의 필요성 제시 

### 1-2 Bounding Box Regression
- Selective Search를 하고 Bounding Box Regression을 왜 적용할까? - Selective Search에서 정확한 좌표가 나오지 않기 때문이다. 

- 여기서 p는 Selective Search에서 나오는 좌표들이고, g는 ground true bounding box이다. d=t함수를 찾는 것이 Bounding Box Regression의 목표이다. 

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91649579-81243980-eab0-11ea-971a-4e5035af74d7.png' alt='drawing' width='600'/></p>

- [C:\Users\sb020\OneDrive\백업완료_2020.03\ML\알파프로젝트\Faster-Rcnn\] 의 필기자료.

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91649654-04458f80-eab1-11ea-9d1f-fe4dd025aba8.png' alt='drawing' width='600'/></p>


# 2. SPP(Spatial Pyramid Pooling) Net
- Fast Rcnn 이전의 RCNN을 개선한 모델이라고 할 수 있다. 
- **Pyramid Pooling** 에서 **ROI Pooling**으로 바꾼게 Fast Rcnn이라고 할 수 있다. 
- Selective Search에서 나온 영역 모두를 DNN에 통과시키는게 아니라, 먼저 DNN에 통과시키고 Feature map에 대해서 Selective Search에서 제안한 영역을 바라 본다. 

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91649906-b67e5680-eab3-11ea-9e9e-c6670d10cc08.png' alt='drawing' width='500'/></p>

- 여기서 문제가 있다. Feature Map에서 FC로 갈 때, FC에 들어가야하는 Input은 고정적이다. 하지만 Selective Search에서 Mapping된 Feature의 사이즈들이 서로서로 다르다. Ex[13x13x256, 9x9x256 등등..]
- Spatial Pyramid Pooling이 Fature map과 FC 사이에서 동작한다. Spatial Pyramid Poolings는 위의 예시와 같은 다른 사이즈의 Feature Map을 Pooling을 통해서 동일한 크기의  Feature Map으로 바꾸고 그것을 FC에 넣음으로써 문제를 해결했다. (ROI Pooing과 거의 동일)
- Spatial Pyramid Matching 기법이라는 컴퓨터 비전의 전통적인 방법을 가져온 것이 Spatial Pyramid Pooling이다. 또 Spatial Pyramid Matching 기법은 Bag of Visual words방법에 근간 한다. 따라서 흐름도는 다음과 같이 그릴 수 있다. SPP가 가장 간단하다.    
  - Bag of Visual words   --->   Spatial Pyramid Matching  --->   Spatial Pyramid Pooling

    <p align="center"><img src='https://user-images.githubusercontent.com/46951365/91650101-2d1c5380-eab6-11ea-8ac5-4bdac44c9582.png' alt='drawing' width='800'/></p>

- 위와 같은 방식으로 어떤 크기의 Feature라고 하더라도 21개의 백터값으로 표현할 수 있었다. 이것을 고정된 값이므로 FC로 넣는데 매우 용이했다. 아래의 사진 하단에서 Feature Map의 크기가 어떤 것이라고 할지라도, 21x256개의 값을 FC에 쉽게 넣을 수 있었다. 

<p align="center"><img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbM9QRL%2FbtqASygWEdX%2FzDNFjvuWgUTFsxG9r0sFSK%2Fimg.png' alt='drawing' width='300'/></p>

- SPP Net을 사용함으로써 RCNN에 비교해서 성능은 비슷하지만, Inference 시간이 20배 정도 줄었다. 

# 3. Fast RCNN

- 위에서 공부한 Spatial Pyramid Pooling을 ROI Pooling으로 바꿨다. SPP처럼 굳이 Level0 Level1 Level2 로 만들지 않고, 7*7의 grid로만 쪼개고 **Max Pooling**과정을 거친다. 

- End-to-End Learning을 수행했다. SVM을 Softmax로 다시 변환했다. 이전까지는 Classification과 Regression을 따로따로 학습시켰는데, 이제는 Multi-task Loss함수를 적용해서 함께 학습시키는 방법을 고안했다.

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91650701-c733ca00-eabd-11ea-9ec5-c52c4d7c9f0f.png' alt='drawing' width='600'/></p>


<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91650716-0a8e3880-eabe-11ea-9ab9-b7f8f861f4ed.png' alt='drawing' width='600'/></p>

- u = 0 이면 Background라는 것을 의미하고 background에 대해서는 당연히 Bounding box regression을 수행하지 않는다. 감마는 multi-tast loss의 밸런스 상수이다. 

- Fast RCNN은 RCNN보다 조금 성능이 향상되고, 추론 시간이 RCNN보다 빠르다. 하지만 Selective Search를 추가하고 안하고의 시간이 각각 2.3초, 0.32초 인것을 감안했을 때, Region Proposal의 오랜시간이 걸리는 문제점을 해결해야함을 알 수 있었다. 