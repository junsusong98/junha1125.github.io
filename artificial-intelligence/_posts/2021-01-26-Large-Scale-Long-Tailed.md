---
layout: post
title: ã€Domainã€‘Adversarial Discriminative Domain Adaptation = ADDA 
---

- **ë…¼ë¬¸** : [Large-Scale Long-Tailed Recognition in an Open World - y2019-c103](https://arxiv.org/pdf/1904.05160.pdf)

- **ë¶„ë¥˜** : Unsupervised Domain Adaptation

- **ì €ì** : Ziwei Liu1,2âˆ— Zhongqi Miao2âˆ— Xiaohang Zhan1

- **ì½ëŠ” ë°°ê²½** : (citation step1) Open Componunt Domain Adaptationì—ì„œ Memory ê°œë…ì´ ì´í•´ê°€ ì•ˆë˜ì„œ ì½ëŠ” ë…¼ë¬¸. 

- **ì½ìœ¼ë©´ì„œ ìƒê°í•  í¬ì¸íŠ¸** : ë…¼ë¬¸ì´ ì–´ë–¤ íë¦„ìœ¼ë¡œ ì“°ì—¬ì¡ŒëŠ”ì§€ íŒŒì•…í•˜ì. ë‚´ê°€ ë‚˜ì¤‘ì— ì“¸ ìˆ˜ ìˆë„ë¡.

- **[ë™ì˜ìƒ ìë£Œ](https://www.youtube.com/watch?v=A45wrs1g8VA)** 
  - <img src="C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210126160627433.png" alt="image-20210126160627433" style="zoom:80%;" />

- **ëŠë‚€ì **  
  1. Instructionì´ ê°œê°™ì€ ë…¼ë¬¸ì€..
     - abstract ë¹ ë¥´ê²Œ ì½ê³ , Introduction ëŒ€ì¶© ì½ì–´ ë„˜ê²¨ì•¼ ê² ë‹¤. ë­”ì†Œë¦¬í•˜ëŠ”ì§€ ë„ì €íˆ!!!!!! ëª¨ë¥´ê² ë‹¤. 
     - ì§€ë‚´ë“¤ì´ í•œ ê³¼ì •ë“¤ì„ ìš”ì•½ì„ í•´ë†¨ëŠ”ë°.. ë‚˜ëŠ” ì •í™•íˆ ì•Œì§€ë„ ëª»í•˜ëŠ”ë° ìš”ì•½ë³¸ì„ ì½ìœ¼ë ¤ë‹ˆê¹Œ ë” ëª¨ë¥´ê² ë‹¤.
     - ë”°ë¼ì„œ ê·¸ëƒ¥ abstractì½ê³  introduction ëŒ€ì¶© ëª¨ë¥´ëŠ”ê±° ê± ë„˜ì–´ê°€ì„œ ì½ê³ . 
     - relative workì˜ ìƒˆë¡œìš´ ê°œë…ë§Œ ë¹ ë¥´ê²Œ í›‘ê³ , ë°”ë¡œ Ours Modelì— ëŒ€í•œ ë‚´ìš©ë“¤ì„ ë¨¼ì € ê¹Šê²Œ ì½ì. ê·¸ë¦¼ê³¼ í•¨ê»˜ ì´í•´í•˜ë ¤ê³  ë…¸ë ¥í•˜ë©´ì„œ. 
     - ê·¸ë¦¬ê³ ! Introduceì„ ë‹¤ì‹œ ì°¾ì•„ê°€(ğŸ‘‹ğŸ‘‹) ì½ìœ¼ë©°, ë‚´ê°€ ê³µë¶€í–ˆë˜ ë‚´ìš©ë“¤ì˜ ìš”ì•½ë³¸ì„ ì½ì 
  2. ì•„ë¬´ë¦¬ Abstract, Instruction, Relative workë¥¼ ì½ì–´ë„, ì´í•´ê°€ ë˜ëŠ” ì–‘ë„ ì •ë§ ì¡°ê¸ˆì´ê³  ë¨¸ë¦¬ì— ë‚¨ëŠ” ì–‘ë„ ì–¼ë§ˆ ë˜ì§€ ì•ŠëŠ”ë‹¤. ì§€ê¸ˆë„ ìœ„ 2ê°œì—ì„œ í•µì‹¬ì´ ë­ì˜€ëƒê³  ë¬¼ìœ¼ë©´, ëŒ€ë‹µ ëª»í•˜ê² ë‹¤. 
     - í˜„ì¬ì˜ ë¨¸ì‹ ëŸ¬ë‹ ë…¼ë¬¸ë“¤ì´ ë‹¤ ê·¸ëŸ°ê²ƒ ê°™ë‹¤. ê·¸ëƒ¥ ëŒ€ì¶© ì‹ ê²½ë§ì— ë•Œë ¤ ë„£ìœ¼ë‹ˆê¹Œ ì˜ëœë‹¤. 
     - í•˜ì§€ë§Œ ê·¸ ì´ìœ ëŠ” ì§ê´€ì ì¼ ë¿ì´ë‹¤. ë”°ë¼ì„œ ëŒ€ì¶© ì´ë ‡ë‹¤ì €ë ‡ë‹¤ ì‚ê¹Œë»”ì©í•œ ë§ë§Œ ì—„ì²­ ë„£ì–´ë‘”ë‹¤. ì´ëŸ¬ë‹ˆ ì´í•´ê°€ ì•ˆë˜ëŠ”ê²Œ ë„ˆë¬´ë‚˜ ë‹¹ì—°í•˜ë‹¤. 
     - ì´ëŸ° ì ì„ ê³ ë ¤í•´ì„œ, ì¢Œì ˆí•˜ì§€ ì•Šê³  ë…¼ë¬¸ì„ ì½ëŠ” ê²ƒë„ ë§¤ìš° ì¤‘ìš”í•œ ê²ƒ ê°™ë‹¤. (ğŸ‘‹ğŸ‘‹)ì—¬ê¸° ì•„ì§ ì•ˆì½ì—ˆë‹¤ê³ ??? ê±±ì •í•˜ì§€ ë§ˆë¼. í•µì‹¬ Model ì„¤ëª… ë¶€ë¶„ ì½ê³  ì˜¤ë©´ ë” ì´í•´ ì˜ë˜ê³  ë¨¸ë¦¬ì— ë‚¨ëŠ”ê²Œ ë§ì„ê±°ë‹¤. í™”ì´íŒ….

- **ë‹¤ ì½ì€ í›„, í•„ìˆ˜ë¡œ ì½ì–´ì•¼ ê² ë‹¤ê³  ìƒê°ì´ ë“  ë…¼ë¬¸**




## 0. Abstract

- the present & challenges
  1. Real world data often have a long-tailed and open-ended distribution. ì¦‰ ì•„ë˜ì˜ ê·¸ë˜í”„ì˜ xì¶•ì€ classì¢…ë¥˜ë¥¼ ë°ì´í„°ê°€ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•œ ê²ƒì´ê³ , yì¶•ì€ í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ ê°€ì§€ëŠ” ë°ì´í„° ìˆ˜. ë¼ê³  í•  ìˆ˜ ìˆë‹¤. Open ClassëŠ” ìš°ë¦¬ê°€ êµ³ì´ Annotate í•˜ì§€ ì•ŠëŠ” í´ë˜ìŠ¤ì´ë‹¤.
  2. <img src="C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210126154310688.png" alt="image-20210126154310688" style="zoom: 80%;" />
- Ours - ì•„ë˜ ë‚´ìš© ìš”ì•½



## 1. Introduction

-  the past	
   -   ëŒ€ë¶€ë¶„ì˜ ê¸°ë²•ë“¤ì€ Head Class ì¸ì‹ì— ì§‘ì¤‘í•˜ì§€ë§Œ,   
      ìµœê·¼ Tail class ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²•ì´ ì¡´ì¬í•œë‹¤. (=Few-shot Learning)for the small data of tail classes [52, 18]
   
- Ours
   -  ìš°ë¦¬ì˜ ê³¼ì œ(with one integrated algorithm)  
      1) imbalanced classification    
      2) few-shot learning  
      3) open-set recognition  
      ì¦‰. tail recognition robustness and open-set sensitivity:
      
   - Open Long-Tailed Recognition(OLTR) ì´ í•´ê²°í•´ì•¼í•˜ëŠ” ë¬¸ì œ  
     1) how to **share visual knowledge(=concept)** between **head and tail** classes (For **robustness**)  
     2) how to **reduce confusion** between **tail and open** classes (For **sensitivity**)     

   - í•´ê²°ë°©ë²• 

     - <u>2ë²ˆì§¸ í˜ì´ì§€ We develop an OLTR ë¬¸ë‹¨ë¶€í„° ë„ˆë¬´ ì´í•´ê°€ ì–´ë µë‹¤. ë”°ë¼ì„œ ì¼ë‹¨ íŒ¨ìŠ¤í•˜ê³  ë‹¤ì‹œ ì˜¤ì. ìš”ì•½ë³¸ì´ë‹ˆ, êµ¬ì²´ì ìœ¼ë¡œ ê³µë¶€í•˜ê³  ë‚˜ë©´ ì´í•´í•˜ê¸° ì‰¬ìš¸ ê±°ë‹¤. </u> ğŸ‘‹ğŸ‘‹ğŸ‘‹

     - ```sh
       # ì´ì „ì— ì •ë¦¬í•´ ë†“ì€ ìë£Œ. ë‚˜ì¤‘ì— ì™€ì„œ ë‹¤ì‹œ ì°¸ì¡°.
       1 mapping(=dynamic meta-embedding) an image to a feature space  = **a direct feature** computed(embeded) from the input image from the training data   
       2) visual concepts(=visual memory feature) ì´ ì„œë¡œì„œë¡œ ì—°ê´€ëœë‹¤.(associate with) = A visual memory holds **discriminative centroids**     
       3) A summary of **memory activations** from the direct feature   
       ê·¸ë¦¬ê³  combine into a meta-embedding that is enriched particularly for the tail class.
       ```

   

   ## 2. Related Works

   ![image-20210126181200150](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210126181200150.png)

- Imbalanced Classification
  - Classical methods -  under-sampling head classes, over-sampling tail classes, and data instance re-weighting.
  -  Some recent methods - metric learning, hard negative mining, and meta learning.
  - Ours
    - combines the strengths of both metric learning[24, 37] and meta learning[17, 59]
    - Our dynamic meta-embeddingğŸ‘‹ğŸ‘‹ğŸ‘‹
- Few-Shot Learning
  -  ì´ˆê¸°ì˜ ë°©ë²•ë“¤ they often suffer a moderate performance drop for head classes.
  - ìƒˆë¡œìš´ ì‹œë„ : The few-shot learning without forgetting,  incremental few-shot learning.
  - í•˜ì§€ë§Œ : ìœ„ì˜ ëª¨ë“  ë°©ë²•ë“¤ì€, the training set are balanced.
  - In comparison, urs : ğŸ‘‹ğŸ‘‹
- Open-Set(new data set) Recognition
  -  OpenMax [3] : calibrating the output logits
  - OLTR approach incorporatesğŸ‘‹ğŸ‘‹



## 3. Our OLTR Model

![image-20210126184016363](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210126184016363.png)

- ìš°ë¦¬ ëª¨ë¸ì˜ í•µì‹¬ì€ Modulated Attention ê·¸ë¦¬ê³  Dynamic meta-embedding ì´ë‹¤. 
  - **Embedding** ë¶€ë¶„ì€ visual concepts between **head and tail** ê³¼ ê´€ë ¨ê¹Šê³ 
  - **Attention** discriminates(êµ¬ë¶„í•œë‹¤) between **head and tail**
  - **reachability** separates **tail and open** classes
- Our OLTR Model
  - 