---
layout: post
title: 【Self】Self-Supervised-Learning & BYOL(Bootstrap Your Own Latent)
---

- **논문** : [Bootstrap Your Own Latent](https://arxiv.org/abs/2006.07733)
- **분류** : Self-Training
- **참고 사이트** : 
  - Self-training overview: [https://hoya012.github.io/blog/Self-Supervised-Learning-Overview/](https://hoya012.github.io/blog/Self-Supervised-Learning-Overview/)
  - BYOL: [https://hoya012.github.io/blog/byol/](https://hoya012.github.io/blog/byol/)
  - BYOL 발표자료: [https://www.youtube.com/watch?v=BuyWUSPJicM](https://www.youtube.com/watch?v=BuyWUSPJicM)
  - 이전 나의 Post: [Self-Supervised-Learning Basics](https://junha1125.github.io/blog/artificial-intelligence/2021-01-15-Self-supervise/)
- **목차**
  1. Self-training overview
  2. BYOL 발표자료
  3. BYOL 블로그 자료 



---

# Self-training overview

**이전 나의 Post 핵심 정리**     

- Self-Supervision을 통해서 Feature Extrator를 생성하고, 그렇게 얻은 **(self를 해서 얻은) FeatureExtractor**를 가지고, 적은 데이터 만을 가지고 (supervision 처럼) Classifier(가장 마지막 단의 multi layer perceptron)를 학심시켜 모델을 완성한다.

**Self-training overview 블로그 정리** (자세한 내용은 그냥 [블로그](https://hoya012.github.io/blog/Self-Supervised-Learning-Overview/)를 다시 참조할 것)  

-  Image를 이용한 대표적인 pretext task를 정의하여, Self-training을 진행하는 10가지 논문들
  1. Exemplar, 2014 NIPS
  2. Context Prediction, 2015 ICCV
  3. Jigsaw Puzzle, 2016 ECCV
  4. Autoencoder-Base Approaches
     - Denoising Autoencoder 
     - Image Colorization 
     - Context Autoencoder 
     - Split-Brain Autoencoder 
  5. Count, 2017 ICCV
  6. Multi-task, 2017 ICCV
  7. Rotation, 2018 ICLR
- Task & Dataset Generalization of Self-Supervised Learning
  1. `downstream task`: feature extractor를 freeze하고 MLP(1층) classifier를 붙여서, Supervised learning으로 fine-tuning을 진행한다.
  2. (보충설명) Random, Random rescaled는 conv layer가 init된 그 상태에 freeze하고 MLP(1층)만 붙여서 fine-tuning한다. 
  3. 반대로 PASCAL VOC를 이용한 다양한 recognition task에서도 self-sup으로 pretrained한 backbone을 사용하지만 freeze하지 않고, finetuning-all 하여 학습한다.
- 결론 
  - Unlabeled datas가 정말 무수하게 많다면, Self-Supervised Learning도 언젠간 좋은 방법,대안이 될 수 있을 것이다. 



# BOYL Blog overview





강의자료 기다려봐서, 강의자료 공유 받으면 공부하고 아니면 그냥 스스로 필기해서 공부하자!

https://hoya012.github.io/blog/byol/

https://www.youtube.com/watch?v=BuyWUSPJicM

































