---
layout: post
title: 【Denoising】 CycleISP- Real Image Restoration via Improved Data Synthesis
---

- **Paper**: [CycleISP: Real Image Restoration via Improved Data Synthesis](https://arxiv.org/abs/2003.07761)
- **Type**: Denoising 



# 핵심 요약

<img src="/Users/junha/Library/Application Support/typora-user-images/image-20210603100449645.png" alt="image-20210603100449645" style="zoom:80%;" />

- RGB에 noise를 넣는게 아니라, RAW에 noise를 넣어서, noise RGB를 생성한다.
- RGB -> RAW로 만들기 위해서, 카메라 파라미터를 사용하지 않고 복원한다. (generalizability확보 가능, reverse engineering 필요 없음)
- `Real camera noise` 를 모두 고려하여, Denoising을 하려면 RGB에서 denoise하는 것 만으로는 부족하다. RAW, RGB 모두에서 Denoising하는 모델을 개발한다.
- 위 CycleISP 네트워크를 사용해서 만들고 싶은 데이터셋이 이거다. (1) `{RAW_clean, RAW_noisy}` (2) `{sRGBclean, sRGBnoisy}`. 이것을 사용해서 모델을 학습시킨다!







---

---

# CycleISP

# 1. Conclusion, Instruction, Conclusion

- Task: single-image denoising problem (+ color matching problem in stereoscopic cinema)

- **Dataset 부족 문제**

  1. Object Detection, Segmentation은 large annotated datasets 덕분에 좋은 성능을 얻었다. 
  2. low-level vision problems (image denoising, super-resolution, deblurring, etc.) 에서는 데이터 셋이 없다. 
  3. **[Noise -> clean Image]**를 위해서 pixel-wise averaging를 사용하지만, 이는 좋지 않다. 
  4. 왜냐하면 lighting condition change 와 scamera/object motion에 의해서 spatial pixels misalignment, color and brightness mismatch 가 존재하기 때문이다.
  5. **[Clean -> Noise Image]** AWGN(additive white Gaussian noise)를 사용해서 데이터 셋을 생성했다. 이렇게 생성된 모델에 CNN 모델이 잘 동작하지만, Real camera images에서는 잘 동작하지 않는다. 
  6. 왜냐하면, `real camera noise`는 AWGN 뿐만 아니라 **(1)**. Signal-dependent (RAW -> demosaicking -> spatio-chromatically correlated -> ISP pipeline, the shot noise) 와 **(2)**. camera imaging pipeline (RAW에서 RGB를 만드는 ISP 과정 중 일부) **(3)** signal-independent additive Gaussian component(AWGN, the read noise) 에서 발생하기 때문이다. 
  7. 게다가 카메라 종류마다 noise의 성격이 달라서 다양한 카메라로 찍은 사진으로 데이터셋을 만들어야 한다. 

- **이 논문의 특정** 

  1. 이 논문에서는 CycleISP 모델을 사용해서, Denoising을 위한 realistic image pairs(데이터셋)을 직접 만들어 낸다. SOTA 달성 및 다른 모델보다 5배 적은 메모리 효율성을 가진다.

  2. The main idea: (데이터 생성 위해) RGB에 noise를 넣는게 아니라, RAW에 noise를 넣어서, noise RGB를 생성한다. 

     - RGB 에서 denoise를 수행하는 것은, 위의 real camera noise 3가지 요소를 고려하지 않은 것이다. 
     - (Denoising 모델 개발을 위해서) 따라서 RGB 뿐만 아니라 RAW 까지에서도 denoise하는 CNN 모듈을 개발하고 사용했다.

  3. The main challenge: 수많은 RGB 데이터를 RAW로 어떻게 복원할 것인가?

     - [7, CVPR2017] 에서 Camera/ISP의 파라미터(black box, (e.g, color correction matrices and white balance gains))를 이용해서 복원하는 방법을 사용했다. 이 방법은 한 디바이스(카메라)만의 정보를 이용하기에 generalizability가 떨어지고, 사실상 ISP의 black box를 reverse engineering하기는 거의 불가능이다. 
     - 따라서 우리는 이런 파라미터적 지식을 필요로 하지 않는 모델을 만든다.

     



---

# 2. Relative work

- Denoising conventional methods
  1. Denoising 기법은 크게 2가지 였다. 
     - (1) transform coefficients(특정 계수 바꾸기): DCT [61],  wavelets [19, 54] 를 사용해서.
     - (2) Averaging neighborhood values:  similar values [55, 57], along contours [42, 50]를 고려해서.
  2. [8] A non-local algorithm for image denoising(**NLM**, Non-local Means). CVPR, 2005 에서 획기적인 발전. 이것을 기반한 모델들이 나왔을 뿐
- Benchmark Dataset [1, 44] - CVPR2017
- AWGN을 사용한 conventional model [8, 15, 22, 24]
  - AWGN을 사용한 알고리즘, 모델들은 실제 이미지에서 denoise를 효율적으로 하지 못한다.
- SOTA Denoising Deep learning 모델  [**4**, **7**, 25, 28, **45**, 64, 65, 2] 
  1. [4] Real image denoising with feature attention. ICCV, 2019
  2. [7] Unprocessing images for learned raw denoising. CVPR, 2019: Camera/ISP(black box) 정보 이용
  3. [45] Neural nearest neighbors networks. NeurIPS, 2018







---

# 3. CycleISP

![image-20210603165102906](/Users/junha/Library/Application Support/typora-user-images/image-20210603165102906.png)

- Network1. RGB2RAW // Network2. RAW2RGB // **각각 먼저 학습시키고(3.1, 3.2) 나중에 같이 학습시킨다.** 
- 용어 혼동을 위해서 sRGB대신에 RGB를 사용한다. 
- 추가) sRGB란 무언인가.
  - [참고 사이트1](https://stackoverflow.com/questions/50622180/does-pil-image-convertrgb-convert-images-to-srgb-or-adobergb), [참고 사이트2](https://stackoverflow.com/questions/35952564/convert-rgb-to-srgb), [참고 사이트3](https://www.cambridgeincolour.com/tutorials/gamma-correction.htm) 
  - sRGB and Adobe RGB are just *RGB color spaces*. 프린터, 모니터가 어떻게 rendering할 것인지에 대한 규칙이다. JPEG 파일 형식 내부에 적혀 있다. 
  - 이미지 감마보정에 대해서, 추가 공부하기. ([참고사이트 4](https://smartits.tistory.com/130), [참고 사이트5](https://smartits.tistory.com/130))





## 3.1. RGB2RAW Network Branch

- Figure2 에서, 위쪽의 네트워크. RGB, RAW가 모두 제공되는 데이터셋을 사용해서 모델을 학습시킨다. 
- The main goal: Invert ISP effects(예를 들어, tone mapping, gamma correction, color correction, white balance, and other transformations). 그래서 많은 RGB데이터에서 RAW를 생성하는 것.
- Figure의 M1을 통과해서 3-channel을 가지는 feature을 뽑음으로써 원본이미지에서 structural information를 최대한 많이 유지한다.
- Bayer sampling function(=Mosaic) 을 사용해서 RAW image (HxWx1)을 생성한다. [코드](https://github.com/swz30/CycleISP/blob/master/networks/cycleisp.py#L16)에서는 H/2 x W/2 x 4의 RGGB images를 바로 만든다.
- Loss는 아래와 같고, log domain loss를 사용하는 이유는, all the image values에 동등하게 loss를 treatment하기 위해서 이다. 그렇지 않으면 highlight regions에만 집중하여 Network가 학습될 것이다. (??= Image histogram에서 많은 부분을 차지하는 특정 value의 픽셀값들만 학습이 잘 일어나는 것을 막는다. 예를 들어서 어두운 값들은 다 고만고만하다. Dynamic range 개념?) 아래 입실론은 작은 상수값.

![image-20210603165559090](/Users/junha/Library/Application Support/typora-user-images/image-20210603165559090.png)





## 3.2. RAW2RGB Network Branch

- Figure2 에서, 아래쪽의 네트워크. RGB, RAW가 모두 제공되는 데이터셋을 사용해서 모델을 학습시킨다. 
- 이 과정에서는 clean RAW images에서 clean sRGB image 생성을 목표로 한다. Noise injection은 하지 않는다.
- Input으로 들어가는 RAW는 위의 3.1에서 만들어진 데이터 사용하는거 아니고, Supervision 위한 데이터셋을 사용한다.
- **3.2.(1) Color attention unit**
  - Figure2 에서 가장 왼쪽 모듈
  - 모델을 Warming up하기 위해서 MIT-Adobe FiveK dataset을 사용해서 학습시킨다. 이 데이터셋은 다양한 종류의 카메라로 생성된 데이터이기 때문에 다양한 ISP parameter에 의해서 만들어진 RGB 데이터 셋이다. 따라서 그냥 학습시키면 학습이 잘 되지 않는다.
  - Color attention(correlation) unit을 사용해서 학습이 잘 되게 만든다. 다양한 디바이스에서 general하게 동작하는 네트워크를 만든다. 이 모듈을 통해서 RAW2RGB모델에 explicit color attention 을 제공할 수 있다. 
  - RGB이미지가 들어가기전에 강한 Gaussian blur(표준편차 12)를 적용함으로써, color 정보만을 encoding한 attention feature를 만들도록 한다. blur를 적용해서 structural content, fine texture를 제거한다.
- 전체 과정 Loss와 수식은 아래와 같다. 

![image-20210603171237282](/Users/junha/Library/Application Support/typora-user-images/image-20210603171237282.png)







## 3.3. RRG: Recursive Residual Group

- less useful features 위치는 무시하고, useful features에 집중하도록 만든다.

<img src="/Users/junha/Library/Application Support/typora-user-images/image-20210603171404751.png" alt="image-20210603171404751" style="zoom:80%;" />







## 3.4. Joint Fine-tuning of CycleISP

- RGB2RAW에서 나온 RAW output이 RAW2RGB의 input으로 들어간다.

![image-20210603171502600](/Users/junha/Library/Application Support/typora-user-images/image-20210603171502600.png)







## 4. Synthetic Realistic Noise Data Generation

**지금까지 학습시킨 CycleISP 모델을 사용해서 데이터 생성하기!**

- Data for RAW denoising
  - {RAW_clean, RAW_noisy} 생성 
  - The noise injection module 을 이제 "ON" !
  - [코드 부분](https://github.com/swz30/CycleISP/blob/master/utils/noise_sampling.py) 이곳의 함수를 사용해서 노이즈를 넣는다. [7] 논문의 sampling shot/read noise factors를 넣는 방법 그대로 사용.
- Data for sRGB denoising
  - {sRGBclean, sRGBnoisy} 생성
  -  RAWnoisy를 모델에 넣어서 나오는 output을 RGBnoisy로 사용한다. 
  - 추가적은 작업을 여기서 더 한다. SIDD데이터 셋을 이용해서, (1) 추가 데이터 생성 (2) CycleISP 모듈 fine-tuning 한다.    
    <img src="/Users/junha/Library/Application Support/typora-user-images/image-20210603172005653.png" alt="image-20210603172005653" style="zoom:100%;" />
  - 





## 5. Denoising Architecture

위에서 생성한 데이터 셋을 사용해서 새로운 네트워크를 학습시키자! 아래와 똑같은 네트워크를 2개 만들고, 하나는 RAW denoising, 다른 하나는 RGB denoising에 사용한다. input과 output channel만 다르게 해주면 된다. 각각 3,4 사용.

![image-20210603172050114](/Users/junha/Library/Application Support/typora-user-images/image-20210603172050114.png)





---

# 6. Experiments

## 6.1. Real Image Datasets

1. DND [44]: 4개 카메라 / high-resolution / 한 장의 이미지로부터, 20 crops of size 512 × 512 / RAW and sRGB 데이터 제공
2. SIDD [1]: 스마트폰(small sensor size, high resolution = noise 심함) / 5개 스마트폰 / 320+1280 이미지 pair  / RAW and sRGB 데이터 제공
3. MIT-Adobe FiveK dataset [10]: Initial training 으로만 사용. / 5000 RAW images / LibRaw library 사용해서 sRGB 이미지 생성 



## 6.2. Implementation Details

- Train: Adam optimizer / 128 × 128 images / randomly horizontal and vertical flips
- Initial training of CycleISP: MIT-Adobe FiveK dataset [10] 데이터셋 사용. 



---

## 6.3,4 Results

1. **RAW denoising 결과.**   
   ![image-20210603175700345](/Users/junha/Library/Application Support/typora-user-images/image-20210603175700345.png)
2. **RGB denoising 결과.**   
   ![image-20210603180503524](/Users/junha/Library/Application Support/typora-user-images/image-20210603180503524.png)     
   ![image-20210603180735050](/Users/junha/Library/Application Support/typora-user-images/image-20210603180735050.png)     
   ![image-20210603180742320](/Users/junha/Library/Application Support/typora-user-images/image-20210603180742320.png)
3. 











---

---



