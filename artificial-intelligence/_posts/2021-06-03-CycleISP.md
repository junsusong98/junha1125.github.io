---
layout: post
title: 【Denoising】 CycleISP- Real Image Restoration via Improved Data Synthesis
---

- **Paper**: [CycleISP: Real Image Restoration via Improved Data Synthesis](https://arxiv.org/abs/2003.07761)
- **Type**: Denoising 
- Reference: https://www.youtube.com/watch?v=41XKXY--7_E



# 핵심 요약

<img src="https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603100449645.png?raw=tru" alt="image-20210603100449645" style="zoom:80%;" />

- RGB에 noise를 넣는게 아니라, RAW에 noise를 넣어서, {sRGBclean, sRGBnoisy} 데이터셋을 생성한다.
- RGB -> RAW로 만들기 위해서, 카메라 파라미터를 사용하지 않고 복원한다. (generalizability확보 가능, reverse engineering 필요 없음, 이미 존재하는 데이터셋이 다양한 카메라로 찍힌 이미지이므로 괜찮을 거다)
- `Real camera noise` 3가지를 모두 고려하여 Denoising을 하려면 AGWN만을 이용해서 학습시킨 모델로는 부족하다. 
- 위 CycleISP 네트워크를 사용해서 (1) `{RAW_clean, RAW_noisy}` (2) `{sRGBclean, sRGBnoisy}` 데이터셋을 만든다! 
- 이렇게 만든 데이터셋을 사용해서 새로운 Denoising Network를 학습시킨다.







---

---

# CycleISP

# 1. Conclusion, Instruction, Conclusion

- Task: single-image denoising problem (추가실험+ color matching problem in stereoscopic cinema)

- **Dataset 부족 문제**

  1. Object Detection, Segmentation은 large annotated datasets 덕분에 좋은 성능을 얻었다. 
  2. low-level vision problems (image denoising, super-resolution, deblurring, etc.) 에서는 데이터 셋이 없다. 
  3. 지금까지 **[Noise -> clean Image]**를 위해서 `pixel-wise averaging`를 사용했지만, 이는 좋지 않다. 
  4. 왜냐하면 lighting condition change 와 scamera/object motion에 의해 생기는, spatial pixels misalignment, color and brightness mismatch 가 존재하기 때문이다.
  5. 지금까지  **[Clean -> Noise Image]** `AWGN(additive white Gaussian noise)`를 사용해서 데이터 셋을 생성했다. 이렇게 생성된 모델에 CNN 모델이 잘 동작하지만, Real camera images에서는 잘 동작하지 않는다. 
  6. 왜냐하면, `real camera noise`는 AWGN 뿐만 아니라 **(1)**. Signal-dependent (RAW -> demosaicking -> spatio-chromatically correlated -> ISP pipeline, the shot noise) 와 **(2)**. camera imaging pipeline (RAW에서 RGB를 만드는 ISP 과정 중 일부) **(3)** signal-independent additive Gaussian component(AWGN, the read noise) 에서 발생하기 때문이다.     
     <img src="https://user-images.githubusercontent.com/46951365/120776804-90647600-c55f-11eb-807d-d831e113918b.png" alt="image" style="zoom:50%;" />
  7. 게다가 카메라 종류마다 noise의 성격이 달라서 다양한 카메라로 찍은 사진으로 데이터셋을 만들어야 한다. 

- **이 논문의 특정** 

  1. 이 논문에서는 CycleISP 모델을 사용해서, Denoising을 위한 realistic image pairs(데이터셋)을 직접 만들어 낸다. SOTA 달성 및 다른 모델보다 5배 적은 메모리 효율성을 가진다.

  2. The main idea: (데이터 생성 위해) RGB에 noise를 넣는게 아니라, RAW에 noise를 넣어서, {sRGBclean, sRGBnoisy} 데이터셋을 생성한다.

     - RGB 에서 AGWN만을 사용해 RGBnoise를 만드는 것은 위의 real camera noise 3가지 요소를 고려하지 않은 것이다. 
     - 추가로, RGB 뿐만 아니라 RAW 까지에서도 denoise하는 CNN 모듈을 개발했다.

  3. The main challenge: 수많은 RGB 데이터를 RAW로 어떻게 복원할 것인가?

     - [7, CVPR2017] 에서 Camera/ISP의 파라미터(black box, (e.g, color correction matrices and white balance gains))를 이용해서 복원하는 방법을 사용했다. 이 방법은 한 디바이스(카메라)만의 정보를 이용하기에 generalizability가 떨어지고, 사실상 ISP의 black box를 reverse engineering하기는 거의 불가능이다. 
     - 따라서 우리는 이런 파라미터적 지식을 필요로 하지 않는 모델을 만든다.

     



---

# 2. Relative work

- Denoising conventional methods
  1. Denoising 기법은 크게 2가지 였다. 
     - (1) transform coefficients(특정 계수 바꾸기): DCT [61],  wavelets [19, 54] 를 사용해서.
     - (2) Averaging neighborhood values:  similar values [55, 57], along contours [42, 50]를 고려해서.
  2. [8] A non-local algorithm for image denoising(**NLM**, Non-local Means). CVPR, 2005 에서 획기적인 발전. 이것을 기반한 모델들이 나왔을 뿐
- Benchmark Dataset [1, 44] - CVPR2017
- AWGN을 사용한 conventional model [8, 15, 22, 24]
  - AWGN을 사용한 알고리즘, 모델들은 실제 이미지에서 denoise를 효율적으로 하지 못한다.
- SOTA Denoising Deep learning 모델  [**4**, **7**, 25, 28, **45**, 64, 65, 2] 
  1. [4] Real image denoising with feature attention. ICCV, 2019
  2. [7] Unprocessing images for learned raw denoising. CVPR, 2019: Camera/ISP(black box) 정보 이용
  3. [45] Neural nearest neighbors networks. NeurIPS, 2018







---

# 3. CycleISP

![image-20210603165102906](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603165102906.png?raw=tru)

- Network1. RGB2RAW // Network2. RAW2RGB // **각각 먼저 학습시키고(3.1, 3.2) 나중에 같이 학습시킨다.** 
- 용어 혼동을 위해서 sRGB대신에 RGB를 사용한다. 
- 추가) sRGB란 무언인가.
  - [참고 사이트1](https://stackoverflow.com/questions/50622180/does-pil-image-convertrgb-convert-images-to-srgb-or-adobergb), [참고 사이트2](https://stackoverflow.com/questions/35952564/convert-rgb-to-srgb), [참고 사이트3](https://www.cambridgeincolour.com/tutorials/gamma-correction.htm) 
  - sRGB and Adobe RGB are just *RGB color spaces*. 프린터, 모니터가 어떻게 rendering할 것인지에 대한 규칙이다. JPEG 파일 형식 내부에 적혀 있다. 
  - 이미지 감마보정에 대해서, 추가 공부하기. ([참고사이트 4](https://smartits.tistory.com/130), [참고 사이트5](https://smartits.tistory.com/130))





## 3.1. RGB2RAW Network Branch

- Figure2 에서, 위쪽의 네트워크. 
- The main goal: Invert ISP effects(예를 들어, tone mapping, gamma correction, color correction, white balance, and other transformations). 그래서 많은 RGB데이터에서 RAW를 생성하는 것.
- Figure의 M1을 통과해서 3-channel을 가지는 feature을 뽑음으로써 원본이미지에서 structural information를 최대한 많이 유지한다.
- Bayer sampling function(=Mosaic) 을 사용해서 RAW image (HxWx1)을 생성한다. [코드](https://github.com/swz30/CycleISP/blob/master/networks/cycleisp.py#L16)에서는 H/2 x W/2 x 4의 RGGB images를 바로 만든다.
- Loss는 아래와 같고, log domain loss를 사용하는 이유는, all the image values에 동등하게 loss를 treatment하기 위해서 이다. 그렇지 않으면 highlight regions에만 집중하여 Network가 학습된다. 
- [CVPR 2020] Single Image HDR 논문에 따르면, Log domain loss를 사용하는 것이, 더 안정적이고 더 높은 성능을 유지할 수 있다고 한다. linear domain에서는 highlight region(밝은 부분)에서 상대적으로 큰 loss가 발생한다고 한다. 이렇게 되면 밝은 부분에서만 학습이 강하게 일어나므로 안정된 학습이 일어나지 않는다. 다시 말해, 모든 region(밝든 어둡든) 부분에서 학습이 적절히 일어나게 하기 위해서 log domain loss를 사용한다. 

![image-20210603165559090](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603165559090.png?raw=tru)





## 3.2. RAW2RGB Network Branch

- Figure2 에서, 아래쪽의 네트워크. 
- 이 과정에서는 clean RAW images에서 clean sRGB image 생성을 목표로 한다. Noise injection은 하지 않는다.
- Input으로 들어가는 RAW는 위의 3.1에서 만들어진 데이터 사용하는거 아니고, Benchmark 데이터셋을 사용한다.
- **3.2.(1) Color attention unit**
  - Figure2 에서 가장 왼쪽 모듈
  - 모델을 Warming up하기 위해서 MIT-Adobe FiveK dataset을 사용해서 학습시킨다. 이 데이터셋은 다양한 종류의 카메라로 생성된 데이터이기 때문에 다양한 ISP parameter에 의해서 만들어진 RGB 데이터 셋이다. 따라서 그냥 학습시키면 학습이 잘 되지 않는다.
  - Color attention(correlation) unit을 사용해서 학습이 잘 되게 만든다. 다양한 디바이스에서 general하게 동작하는 네트워크를 만든다. 이 모듈을 통해서 RAW2RGB모델에 explicit color attention 을 제공할 수 있다. 
  - RGB이미지가 들어가기전에 강한 Gaussian blur(표준편차 12)를 적용함으로써, color 정보만을 encoding한 attention feature를 만들도록 한다. blur를 적용해서 structural content, fine texture를 제거한다.
- 전체 과정 Loss와 수식은 아래와 같다. 

![image-20210603171237282](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603171237282.png?raw=tru)







## 3.3. RRG: Recursive Residual Group

- less useful features 위치는 무시하고, useful features에 집중하도록 만든다.

<img src="https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603171404751.png?raw=tru" alt="image-20210603171404751" style="zoom:80%;" />







## 3.4. Joint Fine-tuning of CycleISP

- RGB2RAW에서 나온 RAW output이 RAW2RGB의 input으로 들어간다.

![image-20210603171502600](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603171502600.png?raw=tru)







## 4. Synthetic Realistic Noise Data Generation

**지금까지 학습시킨 CycleISP 모델을 사용해서 데이터 생성하기!**

- Data for RAW denoising
  - {RAW_clean, RAW_noisy} 생성 
  - The noise injection module 을 이제 "ON" !
  - [코드 부분](https://github.com/swz30/CycleISP/blob/master/utils/noise_sampling.py) 이곳의 함수를 사용해서 노이즈를 넣는다. [7] 논문의 sampling shot/read noise factors를 넣는 방법 그대로 사용.
- Data for sRGB denoising
  - {sRGBclean, sRGBnoisy} 생성
  -  RAWnoisy를 모델에 넣어서 나오는 output을 RGBnoisy로 사용한다. 
- 추가적은 작업을 여기서 더 한다. SIDD데이터 셋을 이용해서, (1) 추가 데이터 생성 (2) CycleISP 모듈 fine-tuning 한다.    
  <img src="https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603172005653.png?raw=tru" alt="image-20210603172005653" style="zoom:100%;" />
  - 





## 5. Denoising Architecture

위에서 생성한 데이터 셋을 사용해서 새로운 네트워크를 학습시키자! 아래와 똑같은 네트워크를 2개 만들고, 하나는 RAW denoising, 다른 하나는 RGB denoising에 사용한다. input과 output channel만 다르게 해주면 된다. 각각 3,4 사용.

![image-20210603172050114](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603172050114.png?raw=tru)





---

# 6. Experiments

## 6.1. Real Image Datasets

1. DND [44]: 4개 카메라 / high-resolution / 한 장의 이미지로부터, 20 crops of size 512 × 512 / RAW and sRGB 데이터 제공
2. SIDD [1]: 스마트폰(small sensor size, high resolution = noise 심함) / 5개 스마트폰 / 320+1280 이미지 pair  / RAW and sRGB 데이터 제공
3. MIT-Adobe FiveK dataset [10]: Initial training 으로만 사용. / 5000 RAW images / LibRaw library 사용해서 sRGB 이미지 생성 



## 6.2. Implementation Details

- Train: Adam optimizer / 128 × 128 images / randomly horizontal and vertical flips
- Initial training of CycleISP: MIT-Adobe FiveK dataset [10] 데이터셋 사용. 



---

## 6.3,4 Results

1. **RAW denoising 결과.**   
   ![image-20210603175700345](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603175700345.png?raw=tru)
2. **RGB denoising 결과.**   
   ![image-20210603180503524](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603180503524.png?raw=tru)     
   ![image-20210603180735050](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603180735050.png?raw=tru)     
   ![image-20210603180742320](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210603180742320.png?raw=tru)
3. 











---

---



