---
layout: post
title: 【Transformer】DeiT-Training data-efficient image transformers & distillation
---

- **논문** : [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)
- **분류** : Transformer
- **읽는 배경** : 매우 핫함. Facebook AI
- **느낀점** : 
- **참고 사이트** : [Youtube 강의 링크](https://www.youtube.com/watch?v=DjEvzeiWBTo)
- **목차**
  1. DeiT 논문 핵심 정리 
  2. DeiT 보충 내용
  3. DeiT Youtube 필기 내용



---

---

# 1. DeiT 논문 핵심 정리 





# 2. DeiT 보충 내용





---

# 3. DeiT Youtube 필기 내용



