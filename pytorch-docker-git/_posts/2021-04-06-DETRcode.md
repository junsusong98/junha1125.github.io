---
layout: post
title: 【Pytorch】DETR code teardown reports 
---

- DETR github : [https://github.com/facebookresearch/detr](https://github.com/facebookresearch/detr)
- Remarks
  1. Dockerfile 제공
  2. Demo code 제공
- 한글 주석 포함 github 링크
  - [https://github.com/junha1125/DETR-with-Kcomment](https://github.com/junha1125/DETR-with-Kcomment)
  - data 폴더 제외 cp 명령하기 `$ cd ~/DETR-with-Kcomment && rsync -av --progress /workspace/* ./ --exclude 'coco'` 
- 의문 정리 (검색하기)
  - 0.1을 왜 곱해주지??
  - detr.py에 `num_classes = 91 if args.dataset_file != 'coco' else 20` 를 `num_classes = 20 if args.dataset_file != 'coco' else 91` 로 바꾸면, 왜 main.py 에서 디버깅 실행하면 `from models import build_model` 에서 에러가 나는 거지? 에러내용은 아래 사진   
    ![image-20210408170702099](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210408170702099.png?raw=tru)
  - ㅇㅇ



---

# Additions

1. COCO dataset 다운로드 하기    

   ```sh
   $ apt-get install wget
   $ wget https://gist.githubusercontent.com/mkocabas/a6177fc00315403d31572e17700d7fd9/raw/a6ad5e9d7567187b65f222115dffcb4b8667e047/coco.sh
   $ sh coco.sh
   ```

2. dockerfile 
   - 그대로 사용했다가, torchvision 버전 엉망됐다. `requirements.txt`에서 torch, torchvision, sumitit 삭제하고 설치하자.
   - `$ pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html` 
   - docker-hub의 `-runtime` , `-devel` 태크 분석하기. 지금 내가 쓰고 있는게 `pytorch/pytorch:1.5-cuda10.1-cudnn7-runtime`이다. 아래의 단서로 runtime은 그냥 가볍게 만든 우분투, devel은 최대한 다 넣어놓은 우분투 라고 예측할 수 있다.
     1. 지금 runtime image에 wget도 설치가 안되어 있다. 
     2. docker-hub를 보면 runtime은 3.3G 정도, devel은 5.3G 정도이다. 
   
3. vscode에서 pdb이용하기    
   ![image-20210406212137524](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210406212137524.png?raw=tru)
   
   - `$ pip install pdbpp`
   
4. vscode python debugging debug args setting 설정

   - `,"args": ["--batch_size", "1", "--no_aux_loss", "--eval", "--resume", "https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth", "--coco_path", "/workspace/coco"]`

   - 위의 내용을, `/pythonPackage/.vscode/launch.json`의 config 파일에 넣어두기     

     ```sh
     {
          "version": "0.2.0",
          "configurations": [
              {
                  "name": "Python: Current File",
                  "type": "python",
                  "request": "launch",
                  "program": "${file}",
                  "console": "integratedTerminal",
                  "debugOptions" : ["DebugStdLib"],
                  "justMyCode": false,
                  "args" : ["--batch_size", "1", "--no_aux_loss", "--eval", "--resume", "https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth", "--coco_path", "/workspace/coco"]
                }
          ]
      }
     ```

     



---

# detr_demo.py. Inference 흐름 따라가기

- [Github/facebookresearch/detr Code link](https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb)

- Error 해결     

  ```sh
  $ pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html 
  # docker Image 그대로 사용했어야 했다. requirements.txt가 개세끼다
  $ conda install -c conda-forge ipywidgets
  $ pip install pdbpp
  ```

- 주요 코드 설명

  1. `h = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1), self.query_pos.unsqueeze(1)).transpose(0, 1)` 
     - 위의 transformer 함수 내부 : (`(625, 1, 256) + 0.1 * (625(갯수), 1, 256(백터)` , `(100, 1 ,256)`) : **0.1을 왜 곱해주지??**
     - transformer ouput : `(100, 1 ,256)`
     - h.shape : (by transpose) : `(1, 100, 256)`

- 이 코드는 nn.transformer를 그대로 사용하기 때문에.. 여기서 그만 공부..



---

# Evaluation. Inference 흐름 따라가기 

- `main.py`는 train.py 코드도 되고, test.py 코드도 된다. `--eval` 옵션만 넣고 빼주면 된다.

```sh
$ python main.py \
		--batch_size 1\
        --no_aux_loss\
        --eval\
        --resume https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth
        --coco_path /workspace/coco # /path/to/coco
```

- `main.py` 분석해보기

  - `print(args)`       	

    ```sh
    - Namespace(aux_loss=False, backbone='resnet50', batch_size=1, bbox_loss_coef=5, clip_max_norm=0.1, coco_panoptic_path=None, coco_path='/workspace/coco', dataset_file='coco', dec_layers=6, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, dropout=0.1, enc_layers=6, eos_coef=0.1, epochs=300, eval=True, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0001, lr_backbone=1e-05, lr_drop=200, mask_loss_coef=1, masks=False, nheads=8, num_queries=100, num_workers=2, output_dir='', position_embedding='sine', pre_norm=False, remove_difficult=False, resume='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth', seed=42, set_cost_bbox=5, set_cost_class=1, set_cost_giou=2, start_epoch=0, weight_decay=0.0001, world_size=1)
    ```

  - 코드 순서 요약하기    

    1. args 설정 및 seed 설정
    2. model, criterion, postprocessors = build_model(args)
    3. 총 파라메터 갯수 계산 하기
    4. backbone / Transformer-encoder, decoder / detector head 각각의 learning rate를 다르게 주기
    5. optimizer와 ir_scheduler 설정
    6. data_loader 만들어 주기 - 1. dataset 정의 , 2. batchSampler 정의 
    7. coco_api 를 사용한 dataset validation = evaluate AP 계산하는 방법
    8. Model Parameters load 하기(1) - frozen_weights 경로가 있을 경우
    9. Model Parameters load 하기(2.1) - Evaluate 하기 위한 파라메터
    10. Model Parameters load 하기(2.2) - Train 하기 위한 파라메터
    11. Evaluation만 하고 코드 종료(return) (1) model infernece하기 (2) coco api로 AP 구하기
    12. If args.eval=False 이라면, 바로 위 코드 안하고, Traiining 시작하기

- `models/__init__.build_model` : 이 과정을 통해서 모델의 전체 구조, 뼈대, 파라메타가 들어갈 공간만 만드는 것이다. 이 사실을 고려하고 공부하기. forward가 어떻게 되는지 이런거는 신경쓰지 말기. 

  1. `from .backbone import build_backbone`
  2. `from .position_encoding import build_position_encoding`
     - 2가지 방법 embeding 방법 
     - `1. PositionEmbeddingLearned` 
       1. `nn.Embedding`, `nn.init.uniform_` 를 사용해서 row_embed, col_embed 변수 정의하기
       2. `pos = torch.cat([x_emb.unsqueeze(0).repeat(h, 1, 1),y_emb.unsqueeze(1).repeat(1, w, 1)], dim=-1).permute(2, 0, 1).unsqueeze(0).repeat(x.shape[0], 1, 1, 1)`
       3. 최종 pos의 shape : (N장, 256, 25, 25) 여기서 25는 feature map의 width, hight  
     - `2. PositionEmbeddingSine`
       1. ㅇㅇ
  3. `from .transformer import build_transformer`
  4. `from .matcher import build_matcher`

- `evaluate`



---

# New modules

1. **torch.repeat(sizes), torch.expand**

   - sizes (torch.Size or int...) – 각 차원에 대한 반복 수 (The number of times to repeat this tensor along each dimension)     

   ```sh
   >>> x = torch.tensor([1, 2, 3])
   >>> x.repeat(4, 2)
   tensor([[ 1,  2,  3,  1,  2,  3],
           [ 1,  2,  3,  1,  2,  3],
           [ 1,  2,  3,  1,  2,  3],
           [ 1,  2,  3,  1,  2,  3]])
   >>> x.repeat(4, 2, 1).size()
   torch.Size([4, 2, 3])
   
   self.col_embed[:W].unsqueeze(0) >> torch.Size([1, 25, 128])
   self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1) >> torch.Size[25,25,125] 
   ```

2. **torch.flatten(input, start_dim=0 : int, end_dim=-1 : int) → Tensor**

   - h : (1, 256,25,25)
   - h.flatten(2) = h.flatten(start_dim = 2) : (1, 256, 625)

3. **torch.permute(2,0,1)**

   - 차원 치환/교환

   -  (1, 256, 625) ->  (625, 1, 256)

4. **torch.unsqueeze(d)** 

   - d: unsqueeze하고 싶은 차원
   - d =1 -> (625, 256) -> (625, 1,256) 

5. **torch.transpose(*input*, *dim0*, *dim1*)**

   - 딱 2개의 차원을 교환한다

6. **torch.nn.Linear(in_features_int, out_features_int)**

   - forward에 들어갈 수 있는 shape는, 무조건 in_feature_int 차원의 1차원 백터가 아니다!! 아래의 차원이 될 수 있다.
   - Input : `(N,*,H_in)`, 이렇게만 forward로 들어가면 된다. Output: `(N, *, H_out)` 
   -  여기서 `H_in = in_features_int`, `H_out = out_features_int` 이다.
   
7. **argparse**

   - config 파일을 사용해서 환경변수를 저장하기도 하지만, 여기서는 간단하게 argparse만으로 환경변수를 정의했다.
   - `main.py`의 argparse 기법을 사용하면, `args.junha = 1` 만 코드에 추가해줘도 자동으로 새로운 key, valuse가 생성된다.

8. **torch.tensor.numel()**

   - tensor 안에 들어 있는 파라메터 갯수 자연수로 반환

9. **nn.Module.parameters(), nn.Module.named_parameters()** 

   - iteration 이다. 
   - `[p.shape for p in model.parameters()]`, `[p for p in model.parameters()]` 이런식으로 출력해서 보기
   - `[n for n, p in model_without_ddp.named_parameters() if "backbone" in n and p.requires_grad]`
   - `[(n,p) for n, p in model.named_parameters()]`   
     ![image-20210408133142137](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210408133142137.png?raw=tru)

10. **nn.Embedding**

    - [torch.nn.Enbedding documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)
    - `self.row_embed = nn.Embedding(50, 128)`
    - `self.row_embed.weight.shape` = torch.Size([50, 128])

11. **nn.init.uniform_**

    - [torch.nn.init](https://pytorch.org/docs/stable/nn.init.html) 여기에 모델 weight를 init하는 방법이 다 있다. 사용은 아래와 같이 한다.
    - `nn.init.uniform_(self.row_embed.weight)`