---
layout: post
title: 【Pytorch】DETR code teardown reports 
---

- DETR github : [https://github.com/facebookresearch/detr](https://github.com/facebookresearch/detr)
- Remarks
  1. Dockerfile 제공 (사용하지 말기)
  2. Demo code 제공
- 한글 주석 포함 github 링크
  - [https://github.com/junha1125/DETR-with-Kcomment](https://github.com/junha1125/DETR-with-Kcomment)
  - data 폴더 제외 cp 명령하기 `$ cd ~/DETR-with-Kcomment && rsync -av --progress /workspace/* ./ --exclude 'coco'` 
- 의문 정리 (검색하기)
  - 0.1을 왜 곱해주지??
- 의문 해결
  - detr.py에 `num_classes = 91 if args.dataset_file != 'coco' else 20` 를 `num_classes = 20 if args.dataset_file != 'coco' else 91` 로 바꾸면, 왜 main.py 에서 디버깅 실행하면 `from models import build_model` 에서 에러가 나는 거지? 에러내용은 아래 사진 ([해결](https://github.com/facebookresearch/detr/issues/358) - 반성하자)  
  - ㅇㅇ



---

# 1. detr_demo.py. Inference 흐름 따라가기

- [Github/facebookresearch/detr Code link](https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb)

- Error 해결     

  ```sh
  $ pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html 
  # docker Image 그대로 사용했어야 했다. requirements.txt가 개세끼다
  $ conda install -c conda-forge ipywidgets
  $ pip install pdbpp
  ```

- 주요 코드 설명

  1. `h = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1), self.query_pos.unsqueeze(1)).transpose(0, 1)` 
     - 위의 transformer 함수 내부 : (`(625, 1, 256) + 0.1 * (625(갯수), 1, 256(백터)` , `(100, 1 ,256)`) : **0.1을 왜 곱해주지??**
     - transformer ouput : `(100, 1 ,256)`
     - h.shape : (by transpose) : `(1, 100, 256)`

- 이 코드는 nn.transformer를 그대로 사용하기 때문에.. 여기서 그만 공부..



---

# 2. Evaluation. Inference 흐름 따라가기 

- `main.py`는 train.py 코드도 되고, test.py 코드도 된다. `--eval` 옵션만 넣고 빼주면 된다.

```sh
[Terminal]
$ python main.py \
		--batch_size 1\
        --no_aux_loss\
        --eval\
        --resume https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth
        --coco_path /workspace/coco # /path/to/coco

$ python main.py \
       	--batch_size 2\
        --no_aux_loss\
        --eval\
        --resume checkpoints/detr-r50-e632da11.pth\
        --num_workers 4\
        --world_size 2\
        --coco_path /dataset/coco\
        --output_dir result

[Vscode Debugging] 
# ./vscode/launch.json
"args" : ["--batch_size", "2", 
        "--no_aux_loss", 
        "--eval", 
        "--resume", "checkpoints/detr-r50-e632da11.pth", 
        "--num_workers", "4",
        "--world_size", "2",
        "--coco_path", "/dataset/coco",
        "--output_dir", "result"]
```

## 2.1 `main.py` 분석해보기

- `print(args)`       	

  ```sh
  - Namespace(aux_loss=False, backbone='resnet50', batch_size=1, bbox_loss_coef=5, clip_max_norm=0.1, coco_panoptic_path=None, coco_path='/workspace/coco', dataset_file='coco', dec_layers=6, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, dropout=0.1, enc_layers=6, eos_coef=0.1, epochs=300, eval=True, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0001, lr_backbone=1e-05, lr_drop=200, mask_loss_coef=1, masks=False, nheads=8, num_queries=100, num_workers=2, output_dir='', position_embedding='sine', pre_norm=False, remove_difficult=False, resume='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth', seed=42, set_cost_bbox=5, set_cost_class=1, set_cost_giou=2, start_epoch=0, weight_decay=0.0001, world_size=1)
  ```

- 코드 순서 요약하기    

  1. args 설정 및 seed 설정
  2. model, criterion, postprocessors = build_model(args)
  3. 총 파라메터 갯수 계산 하기
  4. backbone / Transformer-encoder, decoder / detector head 각각의 learning rate를 다르게 주기
  5. optimizer와 lr_scheduler 설정
  6. data_loader 만들어 주기 - 1. dataset 정의 , 2. batchSampler 정의 
  7. coco_api 를 사용한 dataset validation = evaluate AP 계산하는 방법
  8. Model Parameters load 하기(1) - frozen_weights 경로가 있을 경우 (= panoptic segmentaion 모듈만 학습시키고 싶은 경우)
  9. Model Parameters load 하기(2.1) - Evaluate 하기 위한 파라메터
  10. Model Parameters load 하기(2.2) - Train 하기 위한 파라메터
  11. Evaluation만 하고 코드 종료(return) (1) model infernece하기 (2) coco api로 AP 구하기
  12. If args.eval=False 이라면, 바로 위 코드 안하고, Traiining 시작하기



## 2.2 models/detr.py 

- 아래로 내려가면서, 함수가 호출된다. build에서 핵심적인 내용반 뽑았다. 

```python
# main.py
from models import build_model
model, criterion, postprocessors = build_model(args)

# models/detr.py
def build(args):
    backbone = build_backbone(args)
    transformer = build_transformer(args)
    model = DETR(backbone, transformer, num_classes=num_classes, num_queries=args.num_queries, aux_loss=args.aux_loss)
    matcher = build_matcher(args)
    criterion = SetCriterion(num_classes, matcher=matcher, weight_dict=weight_dict, eos_coef=args.eos_coef, losses=losses)
    postprocessors = {'bbox': PostProcess()}
    return model, criterion, postprocessors
```

따라서 아래의 과정을 따라서 차근차근 공부해나갈 예정이다. 

1. build_backbone()
2. build_transformer()
3. model = DETR()
4. build_matcher()
5. SetCriterion()
6. PostProcess()



## 2.2.1 models/position_encoding.py /build_position_encoding()

- 2가지 방법 embeding 방법이 존재한다.]

1. Leaned - Positional Embeding
   - `nn.Embedding`, `nn.init.uniform_` 를 사용해서 row_embed, col_embed 변수 정의하기
   - `pos = torch.cat([x_emb.unsqueeze(0).repeat(h, 1, 1),y_emb.unsqueeze(1).repeat(1, w, 1)], dim=-1).permute(2, 0, 1).unsqueeze(0).repeat(x.shape[0], 1, 1, 1)`
   - 최종 pos의 shape : (N장, 256, 25, 25) 여기서 25는 feature map의 width, hight
2. sinusoidal  - Positional Embeding
   - 







## 2.2.2 models/backbone.py /build_backbone()



## 2.2.3 models/transformer.py /build_transformer()



## 2.2.4 models/detr.py /DETR()



## 2.2.5  models/matcher.py /build_matcher()



## 2.2.6 models/detr.py /SetCriterion()



## 2.2.7 models/detr.py /PostProcess()















---

# 3. New modules

1. **torch.repeat(sizes), torch.expand**

   - sizes (torch.Size or int...) – 각 차원에 대한 반복 수 (The number of times to repeat this tensor along each dimension)     

   ```sh
   >>> x = torch.tensor([1, 2, 3])
   >>> x.repeat(4, 2)
   tensor([[ 1,  2,  3,  1,  2,  3],
           [ 1,  2,  3,  1,  2,  3],
           [ 1,  2,  3,  1,  2,  3],
           [ 1,  2,  3,  1,  2,  3]])
   >>> x.repeat(4, 2, 1).size()
   torch.Size([4, 2, 3])
   
   self.col_embed[:W].unsqueeze(0) >> torch.Size([1, 25, 128])
   self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1) >> torch.Size[25,25,125] 
   ```

2. **torch.flatten(input, start_dim=0 : int, end_dim=-1 : int) → Tensor**

   - h : (1, 256,25,25)
   - h.flatten(2) = h.flatten(start_dim = 2) : (1, 256, 625)

3. **torch.permute(2,0,1)**

   - 차원 치환/교환

   -  (1, 256, 625) ->  (625, 1, 256)

4. **torch.unsqueeze(d)** 

   - d: unsqueeze하고 싶은 차원
   - d =1 -> (625, 256) -> (625, 1,256) 

5. **torch.transpose(*input*, *dim0*, *dim1*)**

   - 딱 2개의 차원을 교환한다

6. **torch.nn.Linear(in_features_int, out_features_int)**

   - forward에 들어갈 수 있는 shape는, 무조건 in_feature_int 차원의 1차원 백터가 아니다!! 아래의 차원이 될 수 있다.
   - Input : `(N,*,H_in)`, 이렇게만 forward로 들어가면 된다. Output: `(N, *, H_out)` 
   -  여기서 `H_in = in_features :int`, `H_out = out_features :int` 이다.
   
7. **argparse**

   - config 파일을 사용해서 환경변수를 저장하기도 하지만, 여기서는 간단하게 argparse만으로 환경변수를 정의했다.
   - `main.py`의 argparse 기법을 사용하면, `args.junha = 1` 만 코드에 추가해줘도 자동으로 새로운 key, valuse가 생성된다.

8. **torch.tensor.numel()**

   - tensor 안에 들어 있는 파라메터 갯수 자연수로 반환

9. **nn.Module.named_parameters()**, **nn.Module.parameters()**

   - iteration 이다. 
   - `[p.shape for p in model.parameters()]`, `[p for p in model.parameters()]` 이런식으로 출력해서 보기
   - `[n for n, p in model_without_ddp.named_parameters() if "backbone" in n and p.requires_grad]`
   - `[(n,p) for n, p in model.named_parameters()]`   
     ![image-20210408133142137](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210408133142137.png?raw=tru)

10. **nn.Embedding**

    - [torch.nn.Enbedding documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)
    - `self.row_embed = nn.Embedding(50, 128)`
    - `self.row_embed.weight.shape` = torch.Size([50, 128])

11. **nn.init.uniform_**

    - [torch.nn.init](https://pytorch.org/docs/stable/nn.init.html) 여기에 모델 weight를 init하는 방법이 다 있다. 사용은 아래와 같이 한다.
    - `nn.init.uniform_(self.row_embed.weight)`



---

# 4. Additions

## 4.1 **논문 외 보충 내용**

1. - Attention is All you need의 논문 내용 정리! 같은 색 매칭해서 보기! - 그리기 코드는 맨 아래에 참조    
     ![image-20210416222918201](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210416222918201.png)

   - Sinusoidal  - Positional Embeding Code    

     ```python
     import numpy as np
     d_vector = 256
     num_vector = 625
     PEs = np.empty((num_vector,d_vector))
     
     period = 1000
     for i in range(num_vector):
         if i%2 == 0:
             w = 1/ period**(2*i/d_vector)
             pos = np.arange(256)
             PEs[i] = np.sin(pos*w)
         if i%2 != 0:    
             w = 1/ period**(2*i/d_vector)
             pos = np.arange(256)
             PEs[i] = np.cos(pos*w)
     
     %matplotlib inline
     import matplotlib.pyplot as plt
     from matplotlib.pyplot import figure
     
     figure(figsize=(25, 23), dpi=80, facecolor='black')
     imgplot = plt.imshow(PEs)
     plt.colorbar()
     ```

2. Multi head self attention에서 **Mask** 개념, **Masked** Self-attention

   - Reference
     1. Transformer를 정말 **완벽**하게 표현설명한 [외국 블로그글](https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0)
     2. Transformer 코드 잘 만들어 놓은 [한국 블로그글](https://paul-hyun.github.io/transformer-02/)
     3. Transformer Architecture를 도식그림으로 잘 그려놓은 [한국 블로그글](https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225)
     4. Teacher forcing을 잘 설명해 놓은 [한국 블로그글](https://lv99.tistory.com/26) 
   - NLP에서 Mask는 Decoder에서 사용되어야 하는 Layer이다. Decoder에서 3번쨰 단어(fine)를 예측할 때, Decoder의 (Emcoder 결과 말고) Input(I, am)으로 2개의 단어가 들어간다. 학습할 때 우리는 Input(I, am, find)를 모두 가지고 있으므로, find은 가린체로 decoder의 Input으로 넣어줘야한다. 그게 Mask가 하는 역할이다.    
   -  Mask가 처리되어야 하는 부분은 다른 곳이 아니라 저 부분만 이다. 그래서 Masked 개념은 Decoder에서만 사용된다.    ![image-20210417165538067](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210417165538067.png)
   - Mask를 이용한 연산 처리 방법    
     ![image-20210417170332292](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210417170332292.png)



## 4.2 추가 추신

1. **COCO dataset 다운로드 하기**    

   ```sh
   $ apt-get install wget
   $ wget https://gist.githubusercontent.com/mkocabas/a6177fc00315403d31572e17700d7fd9/raw/a6ad5e9d7567187b65f222115dffcb4b8667e047/coco.sh
   $ sh coco.sh
   ```

2. **dockerfile** 

   - 그대로 사용했다가, torchvision 버전 엉망됐다. `requirements.txt`에서 torch, torchvision, sumitit 삭제하고 설치하자.
   - `$ pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html` 
   - docker-hub의 `-runtime` , `-devel` 태크 분석하기. 지금 내가 쓰고 있는게 `pytorch/pytorch:1.5-cuda10.1-cudnn7-runtime`이다. 아래의 단서로 runtime은 그냥 가볍게 만든 우분투, devel은 최대한 다 넣어놓은 우분투 라고 예측할 수 있다.
     1. 지금 runtime image에 wget도 설치가 안되어 있다. 
     2. docker-hub를 보면 runtime은 3.3G 정도, devel은 5.3G 정도이다. 

3. **vscode에서 pdb이용하기**    
   ![image-20210406212137524](https://github.com/junha1125/Imgaes_For_GitBlog/blob/master/Typora-rcv/image-20210406212137524.png?raw=tru)

   - `$ pip install pdbpp`

4. **vscode python debugging debug args setting 설정**

   - `,"args": ["--batch_size", "1", "--no_aux_loss", "--eval", "--resume", "https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth", "--coco_path", "/workspace/coco"]`

   - 위의 내용을, `/pythonPackage/.vscode/launch.json`의 config 파일에 넣어두기     

     ```sh
     {
          "version": "0.2.0",
          "configurations": [
              {
                  "name": "Python: Current File",
                  "type": "python",
                  "request": "launch",
                  "program": "${file}",
                  "console": "integratedTerminal",
                  "debugOptions" : ["DebugStdLib"],
                  "justMyCode": false,
                  "args" : ["--batch_size", "1", "--no_aux_loss", "--eval", "--resume", "https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth", "--coco_path", "/workspace/coco"]
                }
          ]
      }
     ```

5. Pytorch 분산학습

   - rank, world size 을 detr에서 설정해줘야 Multi-GPU사용이 가능한데, 이게 뭔지모르니까 막무가네로 확경변수 설정 못하겠다. 
   - 필요하면 다음의 Tuturial을 공부하자. [Tuto1](https://pytorch.org/tutorials/beginner/dist_overview.html) [Tuto2](https://pytorch.org/docs/stable/distributed.html)

